# Getting Started Guide
Welcome to the getting started guide of `gcdt`. In this guide we will cover what `gcdt` is and how to use it to
create beautiful infrastructure as code (IaC):
* using AWS Cloudformation with `kumo`
* deploy and configure AWS Lambda with `ramuda`
* deploy your application with AWS Codedeploy scripts and `tenkai`
* deploy API and manage API keys with `yugen`
All of these things you could do for different Environments (dev, stage, prod)
## Infrastructure as code
Infrastructure as Code (IaC) is a type of IT infrastructure that teams can automatically manage and provision through code, rather than using a manual process. Through defining your infrastructure as code you will solve a lot of problems since code is:
- portable
- reusable
- shareable
- testable.
## Installation
### Install Python
First of all you need to have Python installed. Python should be 2.7 or higher

**On MacOS try to use preinstalled Python**

### Install pip and virtualenv
[virtualenv](http://python-guide-pt-br.readthedocs.io/en/latest/dev/virtualenvs/) is a tool to create isolated Python environments. virtualenv creates a folder which contains all the necessary executables to use the packages that a Python project would need.
#### MacOS
```bash
$ sudo pip install virtualenv --upgrade
```
### Install gcdt and gcdt plugins
#### Install gcdt
First of all you need to create virtualenv and activate it. It's pretty easy.
```bash
$ virtualenv venv
$ source ./venv/bin/activate
$ pip install pip --upgrade
```
gcdt needs some `gcdt-glugins` so you should install these together. `gcdt-glugins` are powerful tool to add features to `gcdt` without having to directly modify the `gcdt` core. The easiest way is to put the dependencies into a *requirements_gcdt.txt* file:
```bash
gcdt
gcdt-config-reader
gcdt-lookups
gcdt-bundler
gcdt-slack-integration
gcdt-datadog-integration
```
You can find more information about plugins in [docs](http://gcdt.readthedocs.io/en/latest/gcdt_plugins/index.html)
then
```bash
$ pip install -r requirements_gcdt.txt
```
To check that everything is good and `gcdt` installed just do:
```bash
$ gcdt version
ERROR: 'ENV' environment variable not set!
```
`ENV` is environment variables which is required for recognizing what config file to use. Usually you have three different config file for each environment (dev, stage, prod). Use ENV to point `gcdt` what config file to use. You should specify it before running any `gcdt` command.
```bash
$ export ENV=dev # gcdt will use gcdt_dev.json config file
$ gcdt version
gcdt version 0.1.403
gcdt plugins:
 * gcdt-config-reader version 0.0.17
 * glomex-config-reader version 0.0.18
 * gcdt-slack-integration version 0.0.14
 * gcdt-datadog-integration version 0.0.15
 * gcdt-lookups version 0.0.17
```

## Kumo
Kumo is a tool which help you to manage and deploy your infrastructure using Cloudformation templates which are generated by [troposphere](https://github.com/cloudtools/troposphere). With kumo you can easily create infrastructure for different Environments(dev, stage, prod).

### Create your first stack with kumo
First of all you need to create two files:
* *cloudformation.py* - here you will describe your infrastructure using `troposphere`
* *gcdt_(dev|stage|prod)* - settings for your ENV in `json` format, needs to include all parameters for the cloudformation template + stack name. You should have separate config for each ENV.

Let's create a simple `gcdts_dev.json`*(please change all values according your AWS account)*:
```bash
{
  "kumo": {
    "StackName": "gcdt-sample-stack",
    "VPCId": "lookup:stack:<stack-name>:DefaultVPCId",
    "ScaleMinCapacity": "1",
    "ScaleMaxCapacity": "1",
    "InstanceType": "t2.micro",
    "DefaultInstancePolicyARN": "lookup:stack:<stack-name>:DefaultInstancePolicyARN",
    "AMI": "lookup:baseami"
  }
}
```
The values for `VPCId` and `DefaultInstancePolicyARN` are filled by by the `gcdt-lookups` which then will be used in the template. The `gcdt-lookups` plugin will search the outputs in the CloudFormation stack (as mentioned in the config).

*Instead of `<stack-name>` you should provide your stack name or use hardcoded value(not recommended).*
It's time to create our first Infrastructure as Code. Let's do this.
Here is simple [cloudformation.py](https://github.com/glomex/gcdt-sample-stack/blob/master/infrastructure/cloudformation.py) script. Use it as a template for creating your infrastructure.

### Deploy stack to AWS
Before running deployment we need to set some necessary ENV variables. **Remember**: You need this ENV variables exported each time before running any `gcdt` command.
```bash
$ export ENV=dev
$ export AWS_DEFAULT_PROFILE=glomex # Default profile. Generated by aws-mfa
$ export AWS_DEFAULT_REGION=eu-west-1
```
Run your first infrastructure deployment. It's really easy.
```bash
$ kumo deploy
```
![Kumo deploy output](_static/gifs/kumo_deploy_output.gif "Kumo_Deploy_Output")
**More information about `kumo` you can find in [docs](http://gcdt.readthedocs.io/en/latest/20_kumo.html)**

## Ramuda
Ramuda will help you to deploy, manage and control AWS Lambda. Ramuda supported runtimes are: **nodejs4.3, nodejs6.10, python2.7, python3.6**
### Deploy simple AWS Lambda
Create `gcdt_(dev|stage|prod)` file or update if you create it with `kumo` *(please change all values according your AWS account)*:
```bash
"ramuda": {
  "bundling": {
    "folders": [
        {
            "source": "./node_modules",
            "target": "./node_modules"
        }
    ],
    "zip": "bundle.zip"
  },
  "lambda": {
    "name" = "jenkins-gcdt-lifecycle-for-ramuda",
    "description" = "lambda test for ramuda",
    "role" = "lookup:stack:<stack-name>:LambdaArnForDeploy",
    "handlerFunction" = "handler.handle",
    "handlerFile" = "handler.py",
    "timeout" = "300",
    "memorySize" = "256",
    "vpc": {
            "subnetIds": [
                "lookup:stack:<stack-name>:LambdaSubnetIda",
                "lookup:stack:<stack-name>:LambdaSubnetIdb",
                "lookup:stack:<stack-name>:LambdaSubnetIdc"
            ],
        }
  }
}
```
then do:
```bash
$ ramuda deploy
```
**More information about `ramuda` you can find in [docs](http://gcdt.readthedocs.io/en/latest/40_ramuda.html)**

## Tenkai
tenkai will help you to deploy your application using AWS [Codedeploy](https://aws.amazon.com/codedeploy/).
tenkai will create bundle and upload it to s3 with all files that you have in `codedeploy` folder. Create or update `gcdt_(dev|stage|prod)` file *(please change all values according your AWS account)*:
```bash
"tenkai": {
  "codedeploy": {
    "applicationName": "lookup:stack:gcdt-sample-stack:applicationName",
    "deploymentGroupName": "lookup:stack:gcdt-sample-stack:DeploymentGroup",
    "deploymentConfigName": "lookup:stack:gcdt-sample-stack:DeploymentConfig",
    "artifactsBucket": "lookup:stack:<stack-name>:s3DeploymentBucket"
  }
}
```
then do:
```bash
$ tenkai deploy
```
**More information about `tenkai` you can find in [docs](http://gcdt.readthedocs.io/en/latest/30_tenkai.html)**

## Yugen
yugen is a tool that will help you to deploy and manage your API with AWS API Gateway. All you need is top put your `swagger.yml` into the same folder as a `gcdt_(dev|stage|prod)` file. Also, add some new configs into it *(please change all values according your AWS account)*:
```bash
"yugen": {
    "api": {
        "apiKey": "xxxxxxxxxxxxxx",
        "description": "Gcdt sample API based on dp api-mock",
        "name": "jenkins-gcdt-sample-api-dev",
        "targetStage": "mock"
    }
}
```
**More information about `yugen` you can find in [docs](http://gcdt.readthedocs.io/en/latest/50_yugen.html)**
